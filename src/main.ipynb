{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9885807,"sourceType":"datasetVersion","datasetId":6070720}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nfrom datasets import Dataset\n\nDATA_DIR = Path(\"/kaggle/input/asl-cv/data\")\n\nTRAIN_DATASET = Dataset.load_from_disk(DATA_DIR.joinpath(\"train\"), keep_in_memory=True)\nTRAIN_DATASET = TRAIN_DATASET.with_format(\"torch\")\nDATA_LEN = len(TRAIN_DATASET)\nVAL_COEFF = 0.2\nVAL_LEN = int(VAL_COEFF * DATA_LEN)\nTRAIN_LEN = DATA_LEN - VAL_LEN\nBATCH_SIZE = 64\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T00:27:27.760246Z","iopub.execute_input":"2024-11-14T00:27:27.761019Z","iopub.status.idle":"2024-11-14T00:27:37.464221Z","shell.execute_reply.started":"2024-11-14T00:27:27.760979Z","shell.execute_reply":"2024-11-14T00:27:37.463361Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torchmetrics\nimport lightning as L\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom lightning.pytorch import callbacks\nfrom torchvision.transforms.v2 import functional as transforms\n\nEPOCHS = 64\n\nCALLBACKS = [\n    callbacks.ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=3),\n    callbacks.RichProgressBar(),\n]\nTRAINER = L.Trainer(\n    max_epochs=EPOCHS,\n    callbacks=CALLBACKS,\n    gradient_clip_val=1.0,\n    gradient_clip_algorithm=\"norm\",\n)\n\n\nclass AslTranslator(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.lr = 0.1\n        decoy_tensor = torch.zeros((1, 3, 64, 64))\n\n        conv1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=3,\n                out_channels=32,\n                kernel_size=3,\n            ),\n            nn.GELU(),\n            nn.AvgPool2d(kernel_size=2),\n            nn.Dropout(),\n        )\n\n        conv2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=3,\n            ),\n            nn.GELU(),\n            nn.AvgPool2d(kernel_size=2),\n            nn.Dropout(),\n        )\n\n        self.conv = nn.Sequential(conv1, conv2)\n        with torch.no_grad():\n            decoy_tensor: torch.Tensor = self.conv(decoy_tensor)\n\n        decoy_tensor = torch.flatten(decoy_tensor, start_dim=1)\n        hidden_size = decoy_tensor.size(1)\n\n        linear1 = nn.Sequential(\n            nn.Linear(in_features=hidden_size, out_features=hidden_size // 2),\n            nn.GELU(),\n            nn.Dropout(),\n        )\n\n        linear2 = nn.Sequential(\n            nn.Linear(in_features=hidden_size // 2, out_features=hidden_size // 4),\n            nn.GELU(),\n            nn.Dropout(),\n        )\n\n        self.linear = nn.Sequential(linear1, linear2)\n        with torch.no_grad():\n            decoy_tensor: torch.Tensor = self.linear(decoy_tensor)\n\n        self.classifier = nn.Linear(in_features=decoy_tensor.size(1), out_features=29)\n\n    def forward(self, inputs):\n        x = transforms.to_dtype(inputs, dtype=self.dtype, scale=True)\n        x = transforms.resize(x, [64, 64])\n        x = self.conv(x)\n        x = torch.flatten(x, start_dim=1)\n        x = self.linear(x)\n        logits = self.classifier(x)\n        return logits\n\n    def training_step(self, examples, _):\n        features: torch.Tensor = examples[\"image\"]\n        targets: torch.Tensor = examples[\"label\"]\n\n        logits: torch.Tensor = self(features)\n\n        loss = F.cross_entropy(logits, targets)\n\n        preds = logits.argmax(1)\n        f1 = torchmetrics.functional.f1_score(\n            preds, targets, task=\"multiclass\", num_classes=29\n        )\n        acc = torchmetrics.functional.accuracy(\n            preds, targets, task=\"multiclass\", num_classes=29\n        )\n        recall = torchmetrics.functional.recall(\n            preds, targets, task=\"multiclass\", num_classes=29\n        )\n\n        self.log_dict(\n            {\n                \"train_loss\": loss.item(),\n                \"train_f1\": f1.item(),\n                \"train_acc\": acc.item(),\n                \"train_recall\": recall.item(),\n            },\n            prog_bar=True,\n            batch_size=targets.size(0),\n        )\n\n        return loss\n\n    def validation_step(self, examples, _):\n        features: torch.Tensor = examples[\"image\"]\n        targets: torch.Tensor = examples[\"label\"]\n        logits: torch.Tensor = self(features)\n\n        loss = F.cross_entropy(logits, targets)\n\n        preds = logits.argmax(1)\n        f1 = torchmetrics.functional.f1_score(\n            preds, targets, task=\"multiclass\", num_classes=29\n        )\n        acc = torchmetrics.functional.accuracy(\n            preds, targets, task=\"multiclass\", num_classes=29\n        )\n        recall = torchmetrics.functional.recall(\n            preds, targets, task=\"multiclass\", num_classes=29\n        )\n\n        self.log_dict(\n            {\n                \"val_loss\": loss.item(),\n                \"val_f1\": f1.item(),\n                \"val_acc\": acc.item(),\n                \"val_recall\": recall.item(),\n            },\n            prog_bar=True,\n            batch_size=targets.size(0),\n        )\n\n        return loss\n\n    def predict_step(self, examples, index):\n        features: torch.Tensor = examples[\"image\"]\n        logits: torch.Tensor = self(features)\n\n        preds = logits.argmax(1)\n        return preds\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer, T_max=EPOCHS * (TRAIN_LEN // BATCH_SIZE)\n        )\n\n        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n\n    def configure_callbacks(self):\n        swa = callbacks.StochasticWeightAveraging(swa_lrs=2.0)\n        return [swa]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T00:28:03.174741Z","iopub.execute_input":"2024-11-14T00:28:03.175344Z","iopub.status.idle":"2024-11-14T00:28:03.302005Z","shell.execute_reply.started":"2024-11-14T00:28:03.175291Z","shell.execute_reply":"2024-11-14T00:28:03.301277Z"}},"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport multiprocessing as mp\n\n\nNUM_WORKERS = mp.cpu_count()\nprint(f\"NUM_WORKERS={NUM_WORKERS}\")\n\nmodel = AslTranslator()\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T00:28:06.173757Z","iopub.execute_input":"2024-11-14T00:28:06.174656Z","iopub.status.idle":"2024-11-14T00:28:07.164973Z","shell.execute_reply.started":"2024-11-14T00:28:06.174612Z","shell.execute_reply":"2024-11-14T00:28:07.164010Z"}},"outputs":[{"name":"stdout","text":"NUM_WORKERS=4\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"AslTranslator(\n  (conv): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n      (1): GELU(approximate='none')\n      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (3): Dropout(p=0.5, inplace=False)\n    )\n    (1): Sequential(\n      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n      (1): GELU(approximate='none')\n      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (3): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (linear): Sequential(\n    (0): Sequential(\n      (0): Linear(in_features=12544, out_features=6272, bias=True)\n      (1): GELU(approximate='none')\n      (2): Dropout(p=0.5, inplace=False)\n    )\n    (1): Sequential(\n      (0): Linear(in_features=6272, out_features=3136, bias=True)\n      (1): GELU(approximate='none')\n      (2): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (classifier): Linear(in_features=3136, out_features=29, bias=True)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"split_dataset = TRAIN_DATASET.train_test_split(VAL_COEFF, stratify_by_column=\"label\")\ntrain_dataloader = torch.utils.data.DataLoader(\n    split_dataset[\"train\"],\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    pin_memory=True,\n    num_workers=NUM_WORKERS - 1,\n)\neval_dataloader = torch.utils.data.DataLoader(\n    split_dataset[\"test\"],\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    pin_memory=False,\n    num_workers=NUM_WORKERS - 1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T00:28:09.516748Z","iopub.execute_input":"2024-11-14T00:28:09.517620Z","iopub.status.idle":"2024-11-14T00:28:12.761449Z","shell.execute_reply.started":"2024-11-14T00:28:09.517579Z","shell.execute_reply":"2024-11-14T00:28:12.760702Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"TRAINER.fit(model, train_dataloader, eval_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T00:28:14.337966Z","iopub.execute_input":"2024-11-14T00:28:14.338341Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 14/63 \u001b[38;2;98;6;224m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m179/1088\u001b[0m \u001b[38;5;245m0:00:07 • 0:00:35\u001b[0m \u001b[38;5;249m26.33it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.943   \u001b[0m\n                                                                                  \u001b[37mtrain_f1: 0.656 train_acc: 0.656 \u001b[0m\n                                                                                  \u001b[37mtrain_recall: 0.656 val_loss:    \u001b[0m\n                                                                                  \u001b[37m0.522 val_f1: 0.827 val_acc:     \u001b[0m\n                                                                                  \u001b[37m0.827 val_recall: 0.827          \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 14/63 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">179/1088</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:07 • 0:00:35</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">26.33it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.943   </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_f1: 0.656 train_acc: 0.656 </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_recall: 0.656 val_loss:    </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.522 val_f1: 0.827 val_acc:     </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.827 val_recall: 0.827          </span>\n</pre>\n"},"metadata":{}}],"execution_count":null}]}